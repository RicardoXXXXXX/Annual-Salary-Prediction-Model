{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2022 Semester 1\n",
    "\n",
    "## Assignment 1: Naive Bayes Leaner for Adult Database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student Name(s):** `Lingpeng Xiao`\n",
    "<br>\n",
    "**Student ID(s):** `1025301`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Marking will be applied on the four functions that are defined in this notebook, and to your responses to the questions at the end of this notebook.\n",
    "\n",
    "## General info\n",
    "\n",
    "<b>Due date</b>: Friday, 8 April 2022 7pm\n",
    "\n",
    "<b>Submission method</b>: Canvas submission\n",
    "\n",
    "<b>Submission materials</b>: This iPython notebook is a template which you will use for your Assignment 1 submission. You need to only submitted the completed copy of this iPython notebook.\n",
    "\n",
    "<b>Late submissions</b>: -10% per day up to 5 days (both weekdays and weekends count). Submissions more than 5 days late will not be accepted (resul in a mark of 0).\n",
    "<ul>\n",
    "    <li>one day late, -1.0;</li>\n",
    "    <li>two days late, -2.0;</li>\n",
    "    <li>three days late, -3.0;</li>\n",
    "    <li>four days late, -4.0;</li>\n",
    "    <li>five days late, -5.0;</li>\n",
    "</ul>\n",
    "\n",
    "<b>Extensions</b>: Students who are demonstrably unable to submit a full solution in time due to medical reasons or other trauma, may apply for an extension.  In these cases, you should email <a href=\"mailto:ni.ding@unimelb.edu.au\">Ni Ding</a> as soon as possible after those circumstances arise. If you attend a GP or other health care service as a result of illness, be sure to provide a Health Professional Report (HPR) form (get it from the Special Consideration section of the Student Portal), you will need this form to be filled out if your illness develops into something that later requires a Special Consideration application to be lodged. You should scan the HPR form and send it with the extension requests.\n",
    "\n",
    "<b>Marks</b>: This assignment will be marked out of 20, and make up 20% of your overall mark for this subject.\n",
    "\n",
    "<b>Materials</b>: Use Jupyter Notebook and Python page on Canvas for information on the basic setup required for this class, including an iPython notebook viewer and the python packages NLTK, Numpy, Scipy, Matplotlib, Scikit-Learn. You can use any Python built-in packages, but do not use any other 3rd party packages; if your iPython notebook doesn't run on the marker's machine, you will lose marks. <b> You should use Python 3</b>.  \n",
    "\n",
    "\n",
    "<b>Evaluation</b>: Your iPython notebook should run end-to-end without any errors in a reasonable amount of time, and you must follow all instructions provided below, including specific implementation requirements and instructions for what needs to be printed (please avoid printing output we don't ask for). You should edit the sections below where requested, but leave the rest of the code as is. You should leave the output from running your code in the iPython notebook you submit, to assist with marking. The amount each section is worth is given in parenthesis after the instructions. \n",
    "\n",
    "You will be marked not only on the correctness of your methods, but also the quality and efficency of your code: in particular, you should be careful to use Python built-in functions and operators when appropriate and pick descriptive variable names that adhere to <a href=\"https://www.python.org/dev/peps/pep-0008/\">Python style requirements</a>. If you think it might be unclear what you are doing, you should comment your code to help the marker make sense of it. We reserve the right to deduct up to 2 marks for unreadable or exessively inefficient code.\n",
    "\n",
    "8 of the marks available for this Project will be assigned to whether the four specified Python functions work in a manner consistent with the materials from COMP30027. Any other implementation will not be directly assessed (except insofar as it is required to make these five functions work correctly).\n",
    "\n",
    "12 of the marks will be assigned to your responses to the questions, in terms of both accuracy and insightfulness. We will be looking for evidence that you have an implementation that allows you to explore the problem, but also that you have thought deeply about the data and the behaviour of the Naive Bayes classifier.\n",
    "\n",
    "<b>Updates</b>: Any major changes to the assignment will be announced via Canvas. Minor changes and clarifications will be announced on the discussion board (ED -> Assignments -> A1); we recommend you check it regularly.\n",
    "\n",
    "<b>Academic misconduct</b>: For most people, collaboration will form a natural part of the undertaking of this homework, and we encourge you to discuss it in general terms with other students. However, this ultimately is still an individual task, and so reuse of code or other instances of clear influence will be considered cheating. Please check the <a href=\"https://canvas.lms.unimelb.edu.au/courses/124196/modules#module_662096\">CIS Academic Honesty training</a> for more information. We will be checking submissions for originality and will invoke the University’s <a href=\"http://academichonesty.unimelb.edu.au/policy.html\">Academic Misconduct policy</a> where inappropriate levels of collusion or plagiarism are deemed to have taken place.\n",
    "\n",
    "**IMPORTANT**\n",
    "\n",
    "Please carefully read and fill out the <b>Authorship Declaration</b> form at the bottom of the page. Failure to fill out this form results in the following deductions: \n",
    "<UL TYPE=”square”>\n",
    "<LI>missing Authorship Declaration at the bottom of the page, -5.0\n",
    "<LI>incomplete or unsigned Authorship Declaration at the bottom of the page, -3.0\n",
    "</UL>\n",
    "**NOTE: COMPLETE AND SUBMIT THIS FILE. YOU SHOULD IMPLEMENT FOUR FUNCTIONS AND INCLUDE YOUR ANSWERS TO THE QUESTIONS IN THIS FILE ONLY. NO OTHER SUBMISSION IS REQUIRED.**\n",
    "\n",
    "**Keep your code clean. Adding proper comments to your code is MANDATORY.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Base code [8 marks]\n",
    "\n",
    "Instructions\n",
    "1. Do **not** shuffle the data set\n",
    "2. Treat the attributes as they are(e.g., do **not** convert numeric attributes to categorical or categorical to numeric). Implement a Naive Bayes classifier with appropriate likelihood function for each attribute.\n",
    "3. You should implement the Naive Bayes classifier from scratch. Do **not** use existing implementations/learning algorithms.\n",
    "4. You CANNOT have more than one train or predict function. Both continuous numeric attributes and categorical ones should be trained in one `train()` function, similarly for the `predict()`.  \n",
    "5. Apart from the instructions in point 3, you may use libraries to help you with data reading, representation, maths or evaluation\n",
    "6. Ensure that all and only required information is printed, as indicated in the final three code cells. Failure to adhere to print the required information will result in **[-1 mark]** per case. *(We don't mind details like you print a list or several numbers -- just make sure the information is displayed so that it's easily accessible)\n",
    "7. You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find. \n",
    "8. You should add adequate comments to make your code easily comprehendible.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--IMPORTANT--#\n",
    "#-- Please use 'pip install <missed-pakage>' to download the needed pakage. --#\n",
    "#-- For loading the file, please put the .csv file and .ipynb file in the same folder --#\n",
    "#-----------------------------------------------------------------------------#\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math as m\n",
    "from tabulate import tabulate\n",
    "label_z = 0\n",
    "label_o = 1\n",
    "\n",
    "#This function convert all labels into 0 and 1\n",
    "def convert_label(file):\n",
    "    #For easier reading, change \">50K\" to 1 and \"<=50K\" to 0\n",
    "    file[\"label\"] = file[\"label\"].astype(str).str.replace(\" >50K\", \"1\")\n",
    "    file[\"label\"] = file[\"label\"].astype(str).str.replace(\" <=50K\", \"0\")\n",
    "    return file\n",
    "\n",
    "# This function should prepare the data by reading it from a file and converting it into a useful format for training and testing\n",
    "# and implement 90-10 splitting as specified in the project description.\n",
    "def preprocess(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    #Covert label into int\n",
    "    data = convert_label(data)\n",
    "\n",
    "    split_ratio = 0.9   #The length of the input file\n",
    "    f_len = len(data) #File length\n",
    "    split_num = split_ratio*f_len\n",
    "    #Split data into tranning:%90, test:%10\n",
    "    x_train = data.iloc[: int(split_num), : -1]\n",
    "    x_test =  data.iloc[int(split_num) :, : -1]\n",
    "    y_train = data.iloc[: int(split_num), -1:]\n",
    "    y_test = data.iloc[int(split_num) :,-1:]\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will collect all nominal and numeric attributes\n",
    "#Should iptut x_train\n",
    "def collect_num_and_nom_atts(df):\n",
    "    att_num = len(df.columns)   #Number of all columns(Include the label column)\n",
    "    nom_atts = []\n",
    "    num_atts = []\n",
    "    for i in range(att_num):\n",
    "        if(df.dtypes[i] == 'O'):\n",
    "            nom_atts.append(df.columns[i])\n",
    "        else:\n",
    "            num_atts.append(df.columns[i])\n",
    "    return nom_atts, num_atts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate log prior probabilities\n",
    "def calculate_log_prior(data, label):\n",
    "    count = 0\n",
    "    log_prior = 0\n",
    "    for i in range(len(data)):\n",
    "        if(data['label'].iloc[i] == label):\n",
    "            count +=1 \n",
    "\n",
    "    log_prior = np.log(count/len(data))\n",
    "\n",
    "    return log_prior\n",
    "\n",
    "#Calculate log standard deviation and mean\n",
    "#Input should be x&y_data, \" att\" and \"0/1\"\n",
    "def calculate_sd_and_mean(x_data, y_data, att, label):\n",
    "    count = 0\n",
    "    sd = 0\n",
    "    sum = 0\n",
    "    atts = []\n",
    "    #Loop the data, add values\n",
    "    for i in range(len(x_data)):\n",
    "        #Only add a value if it's picked and not ? \n",
    "        if(y_data[\"label\"].iloc[i] == label and x_data[att].iloc[i] != \"?\"):\n",
    "            count +=1 \n",
    "            atts.append(x_data[att].iloc[i])\n",
    "    mean = np.mean(atts)\n",
    "\n",
    "    for i in range(count):\n",
    "        sum += m.pow((atts[i]-mean), 2)\n",
    "    sd = m.sqrt(sum / (count - 1))\n",
    "\n",
    "    return sd, mean   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store mean and sd of all num attributes\n",
    "#i.e. 'age', 'education num', 'hours per week'\n",
    "def store_sd_and_mean(x_train, y_train, num_atts):\n",
    "    zero_mean_list = []\n",
    "    zero_sd_list = []\n",
    "    one_mean_list = []\n",
    "    one_sd_list = []\n",
    "    dataframe_list = []\n",
    "\n",
    "    #Calculate standard deviation and mean \n",
    "    for att in num_atts:\n",
    "        z_sd, z_mean = calculate_sd_and_mean(x_train, y_train, att, \"0\")\n",
    "        zero_sd_list.append(z_sd) \n",
    "        zero_mean_list.append(z_mean) \n",
    "\n",
    "        o_sd, o_mean = calculate_sd_and_mean(x_train, y_train, att, \"1\")\n",
    "        one_sd_list.append(o_sd) \n",
    "        one_mean_list.append(o_mean)\n",
    "\n",
    "    #Store these lists in a dataframe\n",
    "    dataframe_list.append(zero_sd_list)\n",
    "    dataframe_list.append(zero_mean_list)\n",
    "    dataframe_list.append(one_sd_list)\n",
    "    dataframe_list.append(one_mean_list)\n",
    "\n",
    "    #Build dataframe\n",
    "    data_frame = pd.DataFrame(dataframe_list, \n",
    "    index = [\"zero_sd\", \"zero_mean\", \"one_sd\", \"one_mean\"],\n",
    "    columns=num_atts)\n",
    "    return  data_frame\n",
    "\n",
    "\n",
    "#Count the 0s and 1s of input y_data\n",
    "def count_zeros_and_ones(y_data):\n",
    "    zero_count = 0\n",
    "    one_count = 0\n",
    "\n",
    "    for i in range(len(y_data)):\n",
    "        if(y_data[\"label\"].iloc[i] == \"0\"):\n",
    "            zero_count += 1\n",
    "        else:\n",
    "            one_count += 1\n",
    "    \n",
    "    return zero_count, one_count\n",
    "\n",
    "\n",
    "#Count the likelihood of a specific value of nominal attributs under Y and N conditions\n",
    "#Should input x&&y_data, att, \" value\", sum of 0s&&1s\n",
    "def count_nom_likeliood(x_data, y_data, att, value, z_num, o_num):\n",
    "    one_sum = 0\n",
    "    zero_sum = 0\n",
    "    total_sum = 0\n",
    "    z_freq = 0\n",
    "    o_freq = 0\n",
    "    #Count the total labels number and each labels number\n",
    "    for i in range(len(x_data)):\n",
    "        if(x_data[att].iloc[i] == value and y_data['label'].iloc[i] == \"0\"):\n",
    "            zero_sum += 1\n",
    "            total_sum += 1\n",
    "        elif(x_data[att].iloc[i] == value and y_data['label'].iloc[i] == \"1\"):\n",
    "            one_sum += 1\n",
    "            total_sum += 1\n",
    "    #Calculate label 0 and 1's log frequency\n",
    "    #Ignore result 0 \n",
    "    if (zero_sum/z_num != 0 and one_sum/o_num != 0):\n",
    "        z_freq = np.log(zero_sum/z_num)\n",
    "        o_freq = np.log(one_sum/o_num)\n",
    "\n",
    "    return z_freq, o_freq\n",
    "\n",
    "\n",
    "#Store all the likelihoods of all nomial attributes in a dataframe\n",
    "def store_nom_likelihood(x_data, y_data):\n",
    "    whole_lh_list = []\n",
    "    nom_atts, num_atts = collect_num_and_nom_atts(x_data)\n",
    "    zero_count, one_count = count_zeros_and_ones(y_data)\n",
    "    \n",
    "    #Add all nominal likelihoods into whole_lh_list\n",
    "    #Loop the nominal attributes\n",
    "    for att in nom_atts:\n",
    "        value_list = list(set(x_train[att]))    #The unique attributes\n",
    "        z_lh_list = []\n",
    "        o_lh_list = []\n",
    "        #Loop the unique attributes\n",
    "        for val in value_list:\n",
    "            z_freq, o_freq = count_nom_likeliood(x_train, y_train, att, val, zero_count, one_count)\n",
    "            #Stroe the current 0 and 1 likelihood into seperate lists\n",
    "            z_lh_list.append(z_freq)\n",
    "            o_lh_list.append(o_freq)\n",
    "        #Store the 0 and 1 likelihood as a pair\n",
    "        whole_lh_list.append((z_lh_list, o_lh_list))\n",
    "\n",
    "    #Add whole_lh_list into a dataframe\n",
    "    data_frame = []\n",
    "    for i in range(len(whole_lh_list)):\n",
    "        df = pd.DataFrame([whole_lh_list[i][0], whole_lh_list[i][1]], columns=[list(set(x_train[nom_atts[i]]))])\n",
    "        data_frame.append(df)\n",
    "    return data_frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should calculate prior probabilities and likelihoods (conditional probabilities) from the training data and using\n",
    "# to build a naive Bayes model\n",
    "def train(x_train,y_train):\n",
    "    label_val1 = \"0\"\n",
    "    label_val2 = \"1\"\n",
    "    nom_atts, num_atts = collect_num_and_nom_atts(x_train)\n",
    "\n",
    "    log_prior_zero = calculate_log_prior(y_train, label_val1)\n",
    "    log_prior_one = calculate_log_prior(y_train, label_val2)\n",
    "    prior = pd.DataFrame([log_prior_zero,log_prior_one], columns=[\"log_prior\"])\n",
    "    \n",
    "    df_sd_mean = store_sd_and_mean(x_train, y_train, num_atts)\n",
    "    df_nom_lh = store_nom_likelihood(x_train, y_train)\n",
    "   \n",
    "    return prior, df_sd_mean, df_nom_lh\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the position of the numeric and nominal dttributes\n",
    "def detect_nom_and_num_index(x_data):\n",
    "    nom_index_list = []\n",
    "    num_index_list = []\n",
    "\n",
    "    for i in range(len(x_data.columns)):\n",
    "        if(x_data.dtypes[i] == \"O\"):\n",
    "            nom_index_list.append(i)\n",
    "        else:\n",
    "            num_index_list.append(i)\n",
    "    \n",
    "    return nom_index_list, num_index_list \n",
    "\n",
    "#Calculate log gaussian pdf\n",
    "def calculate_num_likelihood(sd, mean, x_data):\n",
    "    coefficient = 0\n",
    "    power = 0\n",
    "    result = 0\n",
    "    #Don't do anything with \"?\"\n",
    "    if(x_data != \"?\"):\n",
    "        coefficient = 1/(sd*m.sqrt(2*m.pi))\n",
    "        power = -0.5*(m.pow(((x_data - mean) / sd), 2))\n",
    "\n",
    "        if(coefficient*pow(m.e, power) == 0):\n",
    "            result = 0\n",
    "        else:\n",
    "            result = np.log(coefficient*pow(m.e, power))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Sum the numeric likelihood of a single instance's numbers\n",
    "def sum_num_likelihood(num_atts_df, df_sd_mean):\n",
    "    zero_lh = 0\n",
    "    one_lh = 0\n",
    "    \n",
    "    for i in range(len(num_atts_df)):\n",
    "        x_value = num_atts_df[i]\n",
    "\n",
    "        #Calculate likelihood of label 0 \n",
    "        zero_sd = df_sd_mean[num_atts_df.index[i]][label_z]\n",
    "        zero_mean = df_sd_mean[num_atts_df.index[i]][label_o]\n",
    "        zero_lh += calculate_num_likelihood(zero_sd, zero_mean, x_value)\n",
    "\n",
    "        #Calculate likelihood of label 1 \n",
    "        one_sd = df_sd_mean[num_atts_df.index[i]][label_z+2]\n",
    "        one_mean = df_sd_mean[num_atts_df.index[i]][label_o+2]\n",
    "        one_lh += calculate_num_likelihood(one_sd, one_mean, x_value)\n",
    "    \n",
    "    return zero_lh, one_lh\n",
    "\n",
    "#Sum the nominal likelihood of a single instance\n",
    "def sum_nom_likelihood(nom_para, df_nom_lh):\n",
    "    zero_lh = 0\n",
    "    one_lh = 0\n",
    "    nom_atts, num_atts = collect_num_and_nom_atts(x_train)\n",
    "    \n",
    "    #Loop the nominal parameter\n",
    "    for i in range(len(nom_atts)):\n",
    "        x_value = nom_para[i]\n",
    "        #If the current parameter exits in the test case\n",
    "        #calculate the likelihood\n",
    "        if(x_value in df_nom_lh[i].columns):    \n",
    "            zero_lh += df_nom_lh[i][x_value].iloc[label_z][0]\n",
    "            one_lh += df_nom_lh[i][x_value].iloc[label_o][0]\n",
    "    \n",
    "    return zero_lh, one_lh\n",
    "\n",
    "\n",
    "# This function should predict classes for new items in the testing data\n",
    "def predict(x_test, prior, df_sd_mean, df_nom_lh):\n",
    "    predict_list = []\n",
    "    c_list = []\n",
    "    z_o_c_list =[]\n",
    "    nom_index_list, num_index_list = detect_nom_and_num_index(x_train)\n",
    "    \n",
    "    #Log prior for 1 and 0\n",
    "    zero_prior = prior[\"log_prior\"][label_z]\n",
    "    one_prior =  prior[\"log_prior\"][label_o]\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        #Nom and num likelihood of a single instance\n",
    "        zero_num_lh, one_num_lh = sum_num_likelihood(x_test.iloc[i, num_index_list], df_sd_mean)\n",
    "        zero_nom_lh, one_nom_lh = sum_nom_likelihood(x_test.iloc[i, nom_index_list], df_nom_lh)\n",
    "        \n",
    "        #Final posibility of zero and one of a single instance\n",
    "        zero_post_prior = zero_prior + zero_num_lh + zero_nom_lh\n",
    "        one_post_prior = one_prior + one_num_lh + one_nom_lh\n",
    "        #Store zero and one post prior in pairs\n",
    "        z_o_c_list.append([zero_post_prior,one_post_prior])\n",
    "\n",
    "        #Store the prediction (the higher posibility result)\n",
    "        if(zero_post_prior > one_post_prior):\n",
    "            predict_list.append(label_z)\n",
    "            c_list.append(zero_post_prior)\n",
    "        else:\n",
    "            predict_list.append(label_o)\n",
    "            c_list.append(one_post_prior)\n",
    "\n",
    "    return predict_list, c_list, z_o_c_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should evaliate the prediction performance by comparing your model’s class outputs to ground\n",
    "# truth labels, return and output accuracy, confusion matrix and F1 score.\n",
    "\n",
    "def evaluate(predict_list, y_test):\n",
    "    #P = 0; N = 1\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    \n",
    "    #Count each element of confussion table\n",
    "    for i in range(len(predict_list)):\n",
    "        if(predict_list[i] == 0 and y_test[\"label\"].iloc[i] == \"0\"):\n",
    "            TP += 1\n",
    "        elif(predict_list[i] == 0 and y_test[\"label\"].iloc[i] == \"1\"):\n",
    "            FP += 1\n",
    "        elif(predict_list[i] == 1 and y_test[\"label\"].iloc[i] == \"1\"):\n",
    "            TN += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "\n",
    "    #Calculte the ouput values\n",
    "    accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "    matrix = np.matrix([[TP,FN],[FP,TN]])\n",
    "    precision = TP/(TP + FP)\n",
    "    recall = TP/(TP + FN)\n",
    "    f_score = (2 * precision * recall)/(precision + recall)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 score: {f_score}\")\n",
    "    print(f\"Confusion matrix: \\n{matrix}\") \n",
    "    return accuracy, f_score, matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "F1 score: 0.9078947368421053\n",
      "Confusion matrix: \n",
      "[[69  8]\n",
      " [ 6 17]]\n",
      "Attribute vectors of instances [0, 1, 2]: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>work class</th>\n",
       "      <th>education</th>\n",
       "      <th>education num</th>\n",
       "      <th>marital status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>hours per week</th>\n",
       "      <th>native country (region)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>68</td>\n",
       "      <td>?</td>\n",
       "      <td>1st-4th</td>\n",
       "      <td>2</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         work class   education  education num       marital status  \\\n",
       "0   68                  ?     1st-4th              2             Divorced   \n",
       "1   39          State-gov   Bachelors             13        Never-married   \n",
       "2   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "         occupation    relationship    race      sex  hours per week  \\\n",
       "0                 ?   Not-in-family   White   Female              20   \n",
       "1      Adm-clerical   Not-in-family   White     Male              40   \n",
       "2   Exec-managerial         Husband   White     Male              13   \n",
       "\n",
       "  native country (region)  \n",
       "0           United-States  \n",
       "1           United-States  \n",
       "2           United-States  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of instances (N): 1000\n",
      "Number of attributes (F): 11\n",
      "Number of labels (L):  2\n",
      "\n",
      "\n",
      "Predicted class log-probabilities for instance N-3: <=50K: -20.716896981933054, >50K: -19.556273652832147\n",
      "Predicted class ID for instance N-3:  >50K\n",
      "\n",
      "Predicted class log-probabilities for instance N-2: <=50K: -25.339070637730188, >50K: -22.744589775643142\n",
      "Predicted class ID for instance N-2:  >50K\n",
      "\n",
      "Predicted class log-probabilities for instance N-1: <=50K: -16.852794958645738, >50K: -16.716481989445864\n",
      "Predicted class ID for instance N-1:  >50K\n"
     ]
    }
   ],
   "source": [
    "# This cell should act as your \"main\" function where you call the above functions \n",
    "# on the full ADULT data set, and print the evaluation results. [0.33 marks]\n",
    "def convert_label_back(label):\n",
    "    if(label == 0):\n",
    "        return \"<=50K\"\n",
    "    elif(label == 1):\n",
    "        return \">50K\"\n",
    "\n",
    "\n",
    "# First, read in the data and apply your NB model to the ADULT data\n",
    "file = \"adult.csv\"\n",
    "x_train, x_test, y_train, y_test = preprocess(file)\n",
    "prior, df_sd_mean, df_nom_lh = train(x_train,y_train)\n",
    "predict_list, c_list,z_o_c_list = predict(x_test, prior, df_sd_mean, df_nom_lh)\n",
    "\n",
    "# Second, print the full evaluation results from the evaluate() function\n",
    "accuracy, f_score, matrix =  evaluate(predict_list, y_test)\n",
    "\n",
    "\n",
    "# Third, print data statistics and model predictions, as instructed below \n",
    "# N is the total number of instances, F the total number of attributes, L the total number of labels\n",
    "# The \"class probabilities\" may be unnormalized\n",
    "# The \"predicted class ID\" must be in range (0, L)\n",
    "print(\"Attribute vectors of instances [0, 1, 2]: \") # of the first three records in adult.csv\n",
    "display(x_train.head(3))\n",
    "\n",
    "print(f\"\\nNumber of instances (N): {len(x_train)+len(x_test)}\")\n",
    "print(f\"Number of attributes (F): {len(x_train.columns)}\")\n",
    "print(\"Number of labels (L): \", len(set(y_test[\"label\"])))\n",
    "\n",
    "\n",
    "# print out the prediction results of the last three instances\n",
    "pre_label1 = convert_label_back(predict_list[-1])\n",
    "pre_label2 = convert_label_back(predict_list[-2])\n",
    "pre_label3 = convert_label_back(predict_list[-3])\n",
    "\n",
    "print(f\"\\n\\nPredicted class log-probabilities for instance N-3: <=50K: {z_o_c_list[-3][0]}, >50K: {z_o_c_list[-3][1]}\")\n",
    "print(\"Predicted class ID for instance N-3: \", pre_label3)\n",
    "print(f\"\\nPredicted class log-probabilities for instance N-2: <=50K: {z_o_c_list[-2][0]}, >50K: {z_o_c_list[-2][1]}\")\n",
    "print(\"Predicted class ID for instance N-2: \", pre_label2)\n",
    "print(f\"\\nPredicted class log-probabilities for instance N-1: <=50K: {z_o_c_list[-1][0]}, >50K: {z_o_c_list[-1][1]}\")\n",
    "print(\"Predicted class ID for instance N-1: \", pre_label1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Conceptual questions [8 marks for groups of 1] / [16 marks for groups of 2]\n",
    "\n",
    "\n",
    "If you are in a group of 1, you should respond to Q1 and Q2.\n",
    "\n",
    "If you are in a group of 2, you should respond to Q1, Q2, Q3 and Q4.\n",
    "\n",
    "A response to a question should take about 100–250 words. You may need to develope codes or functions to help respond to the question here. \n",
    "\n",
    "#### NOTE: We strongly recommend <u>including figures or tables, etc.</u> to support your responses. The figures and tables inserted in Markdown cells must be reproducable by your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 [4 marks]\n",
    "<u>Sensitivity</u> and <u>specificity</u> are two model evaluation metrics.  A good model should have both sensitivity and specificity high. Use the $2 \\times 2$ confusion matrix returned by `evaluate()` to calculate the sensitivity and specificity. Do you see a difference between them? If so, what causes this difference? Provide suggestions to improve the model performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "| Sensitivity | 0.896104 |\n",
      "+-------------+----------+\n",
      "| Specificity | 0.73913  |\n",
      "+-------------+----------+\n",
      "+-------+--------------+-------------+\n",
      "|       |   Train data |   Test data |\n",
      "+=======+==============+=============+\n",
      "| <=50K |          692 |          75 |\n",
      "+-------+--------------+-------------+\n",
      "| >50K  |          208 |          25 |\n",
      "+-------+--------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#The cell displays the quantity of label values in\n",
    "#y_test and y_train\n",
    "TP = matrix[0, 0]\n",
    "FN = matrix[0, 1]\n",
    "FP = matrix[1, 0]\n",
    "TN = matrix[1, 1]\n",
    "\n",
    "#Display the evaluation results\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "# assign data\n",
    "mydata1 = [[\"Sensitivity\"] + [sensitivity]]\n",
    "mydata2 = [[\"Specificity\"] + [specificity]]\n",
    "mydata_tt = mydata1 + mydata2\n",
    "# display table\n",
    "print(tabulate(mydata_tt, tablefmt=\"grid\"))\n",
    "\n",
    "#Count the label distribution\n",
    "def count_labels(dataset):\n",
    "    count_zero = 0\n",
    "    count_one = 0\n",
    "    #Find the number of 0 and 1\n",
    "    for i in range(len(dataset)):\n",
    "        if(y_train[\"label\"].iloc[i] == \"0\"):\n",
    "            count_zero += 1\n",
    "        elif(y_train[\"label\"].iloc[i] == \"1\"):\n",
    "            count_one += 1\n",
    "\n",
    "    return count_zero, count_one\n",
    "\n",
    "train_zeros, train_ones = count_labels(y_train)\n",
    "test_zeros, test_ones = count_labels(y_test)\n",
    "\n",
    "#Display the label distribution\n",
    "# assign data\n",
    "mydata1 = [[\" <=50K\"] + [train_zeros] + [test_zeros] ]\n",
    "mydata2 = [[\" >50K\"] + [train_ones] + [test_ones]]\n",
    "mydata_tt = mydata1 + mydata2\n",
    "# create header\n",
    "head = [\" \"] + [\"Train data\"]+ [\"Test data\"]\n",
    "# display table\n",
    "print(tabulate(mydata_tt, headers=head, tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity shows the ability of a model to detect the proportion of true positive cases. And, specificity shows the ability about detecting the true negative cases. According to the results, the sensitivity is a bit higher than the specificity, the difference is around 0.1. It means this model performs better in predicting true positive cases.    \n",
    "\n",
    "Based on the data distribution, the overall ratio of label values in the dataset is about 3(<=50K):1(>50K). It means the prior possibility of (<=50K) is greater, and the value of TP will be greater than TN as well. According to the formulas, the model may tend to predict the label as \"<=50K\" due to the greater prior. This may also cause the value of sensitivity to be greater than Specificity because the sensitivity has a greater numerator.\n",
    "\n",
    "For improving this model, balanced labels might be helpful. For example, when there are other extra instances, it's good to pick more data of label \">50K\". On the other hand, picking more instances without missing attributes may also improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 [4 marks]\n",
    "You can adopt different methods for training and/or testing, which will produce different results in model evaluation. \n",
    "\n",
    "(a) Instead of Gaussian, <u>implement KDE</u> for  $P(X_i|c_j)$ for numeric attributes $X_i$. Compare the evaluation results with Gaussian. Which one do you think is more suitable to model $P(X_i|c_j)$, Gaussian or KDE? Observe all numeric attributes and justify your answer.\n",
    "\n",
    "You can choose an arbitrary value for kernel bandwidth $\\sigma$ for KDE, but a value between 3 and 15 is recommended. You should write code to implement KDE, not call an existing function/method such as `KernelDensity` from `scikit-learn`.\n",
    "\n",
    "(b) Implement <u>10-fold and 2-fold cross-validations</u>.  \n",
    "\tObserve the evaluation results in each fold and the average accuracy, recall and specificity over all folds. \n",
    "\tComment on what is the effect by changing the values of $m$ in $m$-fold cross validation. (You can choose either Gaussian or KDE Naive Bayes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This fucntion calculate Gussian pdf\n",
    "def calculate_g_pdf(x, xi, bandwidth):\n",
    "    coefficient = 0\n",
    "    power = 0\n",
    "    result = 0\n",
    "    #Don't do anything with \"?\"\n",
    "    if(x != \"?\" and xi != \"?\"):\n",
    "        coefficient = 1/(bandwidth*m.sqrt(2*m.pi))\n",
    "        power = -0.5*(m.pow(((x - xi) / bandwidth), 2))\n",
    "        result = coefficient*pow(m.e, power)\n",
    "    \n",
    "    return result\n",
    "\n",
    "#This function calculate KDE pdf\n",
    "def calculate_KDE_pdf(x, bandwidth, label_atts):\n",
    "    KDE_list = []\n",
    "    mean = 0\n",
    "    #label_atts inlcudes the rows of the same label(0/1)\n",
    "    #Loop the label_atts, calculate the gaussian pdf of each x_value\n",
    "    for x_value in label_atts.index:\n",
    "        xi = label_atts[x_value]\n",
    "        #Add the result into the list\n",
    "        KDE_list.append(calculate_g_pdf(x, xi, bandwidth))\n",
    "\n",
    "    mean = np.mean(KDE_list)    #The mean of the list\n",
    "    if(mean == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return np.log(mean)\n",
    "\n",
    "#This function store the KED likelihood in a dataframe\n",
    "def store_KED_likelihood(x_train, x_test, y_train, num_atts, bandwidth):\n",
    "    para_list = []\n",
    "    zero_index = y_train.loc[y_train[\"label\"] == \"0\"].index\n",
    "    one_index = y_train.loc[y_train[\"label\"] == \"1\"].index\n",
    "    \n",
    "    #Find each attrtribute with specific labels (0/1) \n",
    "    for att in num_atts:\n",
    "        zero_att = x_train.loc[zero_index, att]\n",
    "        one_att = x_train.loc[one_index, att]\n",
    "\n",
    "        zero_list = []\n",
    "        one_list = []\n",
    "\n",
    "        #Calculate total KDE pdf, the cluster is based on label\n",
    "        for i in x_test.index:\n",
    "            x = x_test[att][i]\n",
    "\n",
    "            zero_list.append(calculate_KDE_pdf(x, bandwidth, zero_att))\n",
    "            one_list.append(calculate_KDE_pdf(x, bandwidth, one_att))\n",
    "        #Add result into a list\n",
    "        para_list.append(zero_list)\n",
    "        para_list.append(one_list)\n",
    "    #Make the list a dataframe\n",
    "    dataframe = pd.DataFrame(para_list, index = [\"zero_age\", \"one_age\", \"zero_education\", \"one_education\", \"zero_h_per_w\", \"one_h_per_w\"])\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function should calculate prior probabilities and likelihoods (conditional probabilities) from the training data and using\n",
    "# to build a naive Bayes model\n",
    "def train_KDE(x_train, x_test, y_train, bandwidth):\n",
    "    label_val1 = \"0\"\n",
    "    label_val2 = \"1\"\n",
    "    nom_atts, num_atts = collect_num_and_nom_atts(x_train)\n",
    "\n",
    "    log_prior_zero = calculate_log_prior(y_train, label_val1)\n",
    "    log_prior_one = calculate_log_prior(y_train, label_val2)\n",
    "    prior = pd.DataFrame([log_prior_zero,log_prior_one], columns=[\"log_prior\"])\n",
    "    \n",
    "    df_KDE_lh = store_KED_likelihood(x_train, x_test, y_train, num_atts, bandwidth)\n",
    "    df_nom_lh = store_nom_likelihood(x_train, y_train)\n",
    "   \n",
    "    return prior, df_KDE_lh, df_nom_lh\n",
    "\n",
    "# This function should predict classes for new items in the testing data\n",
    "def predict_KDE(x_test, prior, df_KDE_lh, df_nom_lh):\n",
    "    predict_list = []\n",
    "    c_list = []\n",
    "    z_o_c_list =[]\n",
    "    nom_index_list, num_index_list = detect_nom_and_num_index(x_train)\n",
    "    \n",
    "    #Log prior for 1 and 0\n",
    "    zero_prior = prior[\"log_prior\"][label_z]\n",
    "    one_prior =  prior[\"log_prior\"][label_o]\n",
    "\n",
    "    for i in range(len(x_test)):\n",
    "        #Nom and num likelihood of a single instance\n",
    "        zero_num_lh = df_KDE_lh[i][\"zero_age\"] + df_KDE_lh[i][\"zero_education\"] + df_KDE_lh[i][\"zero_h_per_w\"]\n",
    "        one_num_lh = df_KDE_lh[i][\"one_age\"] + df_KDE_lh[i][\"one_education\"] + df_KDE_lh[i][\"one_h_per_w\"]\n",
    "        zero_nom_lh, one_nom_lh = sum_nom_likelihood(x_test.iloc[i, nom_index_list], df_nom_lh)\n",
    "        \n",
    "        #Final posibility of zero and one of a single instance\n",
    "        zero_post_prior = zero_prior + zero_num_lh + zero_nom_lh\n",
    "        one_post_prior = one_prior + one_num_lh + one_nom_lh\n",
    "        #Store zero and one post prior in pairs\n",
    "        z_o_c_list.append([zero_post_prior,one_post_prior])\n",
    "\n",
    "        #Store the prediction (the higher posibility result)\n",
    "        if(zero_post_prior > one_post_prior):\n",
    "            predict_list.append(label_z)\n",
    "            c_list.append(zero_post_prior)\n",
    "        else:\n",
    "            predict_list.append(label_o)\n",
    "            c_list.append(one_post_prior)\n",
    "\n",
    "    return predict_list, c_list, z_o_c_list\n",
    "\n",
    "#This function used the previous evlauate function to calculate the \n",
    "#accuracy, F-score and confusion table matrix\n",
    "def evalueate_KDE(x_train, x_test, y_train, y_test, bandwidth):\n",
    "    prior_KDE, df_KDE_lh, df_nom_lh = train_KDE(x_train, x_test, y_train, bandwidth)\n",
    "    predict_list_KDE, c_list_KDE, z_o_c_list_KDE = predict_KDE(x_test, prior_KDE, df_KDE_lh, df_nom_lh)\n",
    "    accuracy_KDE, f_score_KDE, matrix_KDE =  evaluate(predict_list_KDE, y_test)\n",
    "    return accuracy_KDE, f_score_KDE, matrix_KDE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "F1 score: 0.9066666666666665\n",
      "Confusion matrix: \n",
      "[[68  9]\n",
      " [ 5 18]]\n",
      "Accuracy: 0.81\n",
      "F1 score: 0.8689655172413794\n",
      "Confusion matrix: \n",
      "[[63 14]\n",
      " [ 5 18]]\n",
      "Accuracy: 0.82\n",
      "F1 score: 0.8750000000000001\n",
      "Confusion matrix: \n",
      "[[63 14]\n",
      " [ 4 19]]\n",
      "Accuracy: 0.81\n",
      "F1 score: 0.8671328671328672\n",
      "Confusion matrix: \n",
      "[[62 15]\n",
      " [ 4 19]]\n",
      "Accuracy: 0.82\n",
      "F1 score: 0.8750000000000001\n",
      "Confusion matrix: \n",
      "[[63 14]\n",
      " [ 4 19]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This cell is used to detect the results of KED and Gaussian algorithm\n",
    "#and discuss their differences \n",
    "#Check the evaluation from bandwidth 3 to 15, gap is 3.\n",
    "accuracy_KDE_list = []\n",
    "for i in range(3, 16, 3):\n",
    "    accuracy_KDE, f_score_KDE, matrix_KDE = evalueate_KDE(x_train, x_test, y_train, y_test, i)\n",
    "    accuracy_KDE_list.append(accuracy_KDE)\n",
    "\n",
    "\n",
    "x = np.arange(3, 16, 3) \n",
    "y1 = [accuracy]*5\n",
    "y2 = np.array(accuracy_KDE_list)\n",
    "# PLot\n",
    "plt.plot(x, y1) \n",
    "plt.plot(x, y2)\n",
    "\n",
    "# Add Title\n",
    "plt.title(\"Accuracy \") \n",
    "\n",
    "# Add Axes Labels and legend\n",
    "plt.xlabel(\"Bandwidth of KDE\") \n",
    "plt.ylabel(\"Accuracy rate\") \n",
    "plt.legend(['Gaussian','KDE'])\n",
    "# Display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This cell shows the plots of numeric attributes\n",
    "#Can obersve the disttributions of those values\n",
    "age_list = []\n",
    "education_num_list = []\n",
    "h_per_w_list = []\n",
    "num_locs = []\n",
    "nom_locs = []\n",
    "nom_locs, num_locs = detect_nom_and_num_index(x_train)\n",
    "\n",
    "#Store all the numeric attributes of all instances\n",
    "with open(\"adult.csv\",'r') as f: #No need to close file when using 'with ... as ...'s\n",
    "    f.readline()    #Ignore the first line\n",
    "    for line in f:\n",
    "        att_vals = line.strip().split(\",\")\n",
    "        currrent_round = 0\n",
    "        for loc in num_locs:\n",
    "            #Ignore \"?\"\n",
    "            if(not(att_vals[loc]) == \"?\"):\n",
    "                if currrent_round == 0: age_list.append(float(att_vals[loc]))\n",
    "                elif currrent_round == 1: education_num_list.append(float(att_vals[loc]))\n",
    "                elif currrent_round == 2: h_per_w_list.append(float(att_vals[loc]))\n",
    "            currrent_round += 1\n",
    "\n",
    "#Plot numeric data\n",
    "#Observe their data distributions\n",
    "plt.title(\"Age\")\n",
    "plt.hist(np.array(age_list))\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Education num')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(np.array(education_num_list))\n",
    "plt.show()\n",
    "\n",
    "plt.title('Hours per weak')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.hist(np.array(h_per_w_list))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function should evaliate the prediction performance by comparing the model’s class outputs to ground\n",
    "# truth labels, return and output accuracy, recall and specificity\n",
    "\n",
    "def evaluate_cv(predict_list, y_test):\n",
    "    #P = 0; N = 1\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    \n",
    "    #Count each element of confussion table\n",
    "    for i in range(len(predict_list)):\n",
    "        if(predict_list[i] == 0 and y_test[\"label\"].iloc[i] == \"0\"):\n",
    "            TP += 1\n",
    "        elif(predict_list[i] == 0 and y_test[\"label\"].iloc[i] == \"1\"):\n",
    "            FP += 1\n",
    "        elif(predict_list[i] == 1 and y_test[\"label\"].iloc[i] == \"1\"):\n",
    "            TN += 1\n",
    "        else:\n",
    "            FN += 1\n",
    "\n",
    "    #Calculte the ouput values\n",
    "    accuracy_cv = (TP + TN)/(TP + TN + FP + FN)\n",
    "    recall_cv = TP/(TP + FN)\n",
    "    specificity_cv = TN / (TN + FP)\n",
    "\n",
    "    return accuracy_cv, recall_cv, specificity_cv\n",
    "\n",
    "\n",
    "#This function build the k-fold cross validation model\n",
    "def kf_cv_model(filename, k):\n",
    "    file = pd.read_csv(filename)\n",
    "    \n",
    "    #Covert label into int\n",
    "    file = convert_label(file)\n",
    "    file_len = len(file)    #The number of rows\n",
    "    split_rate = 1/k\n",
    "    fold_size = split_rate*file_len   #The size of each fold\n",
    "\n",
    "    accuracy_cv_list = []\n",
    "    recall_cv_list = []\n",
    "    specificity_cv_list = []\n",
    "\n",
    "    for i in range(k):\n",
    "        test_index = []\n",
    "        #The rows index of the test data\n",
    "        test_index = list(range(int(i * fold_size), int((i+1) * fold_size)))\n",
    "        #The rows index of the train data\n",
    "        train_index = file.index.drop(test_index)\n",
    "\n",
    "        #Split the data\n",
    "        x_train_cv = file.iloc[train_index, : -1]\n",
    "        x_test_cv =  file.iloc[test_index, : -1]\n",
    "        y_train_cv = file.iloc[train_index, -1:]\n",
    "        y_test_cv = file.iloc[test_index, -1:]\n",
    "\n",
    "        #Do the train(), predict() and evaluate()\n",
    "        prior_cv, df_sd_mean_cv, df_nom_lh_cv = train(x_train_cv, y_train_cv)\n",
    "        predict_list_cv, c_list_cv,z_o_c_list_cv = predict(x_test_cv, prior_cv, df_sd_mean_cv, df_nom_lh_cv)\n",
    "        accuracy_cv, recall_cv, specificity_cv =  evaluate_cv(predict_list_cv, y_test_cv)\n",
    "\n",
    "        #Store the ressult into lists\n",
    "        accuracy_cv_list.append(accuracy_cv)\n",
    "        recall_cv_list.append(recall_cv)\n",
    "        specificity_cv_list.append(specificity_cv)\n",
    "\n",
    "    return accuracy_cv_list, recall_cv_list, specificity_cv_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the 10-fold CV nad 2-dold CV, store the outputsseperately\n",
    "accuracy_cv_list_10, recall_cv_list_10, specificity_cv_list_10 = kf_cv_model(\"adult.csv\", 10)\n",
    "accuracy_cv_list_2, recall_cv_list_2, specificity_cv_list_2 = kf_cv_model(\"adult.csv\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+----------+----------+----------+------+----------+----------+----------+----------+----------+\n",
      "| Execute order   |    1 |        2 |        3 |        4 |    5 |        6 |        7 |        8 |        9 |       10 |\n",
      "+=================+======+==========+==========+==========+======+==========+==========+==========+==========+==========+\n",
      "| Accuracy        | 0.79 | 0.84     | 0.8      | 0.86     | 0.86 | 0.82     | 0.81     | 0.78     | 0.81     | 0.86     |\n",
      "+-----------------+------+----------+----------+----------+------+----------+----------+----------+----------+----------+\n",
      "| Recall          | 0.76 | 0.833333 | 0.818182 | 0.87013  | 0.9  | 0.835443 | 0.844156 | 0.815789 | 0.849315 | 0.896104 |\n",
      "+-----------------+------+----------+----------+----------+------+----------+----------+----------+----------+----------+\n",
      "| Specificity     | 0.88 | 0.863636 | 0.73913  | 0.826087 | 0.7  | 0.761905 | 0.695652 | 0.666667 | 0.703704 | 0.73913  |\n",
      "+-----------------+------+----------+----------+----------+------+----------+----------+----------+----------+----------+\n",
      "+------------+------------+----------+---------------+\n",
      "|            |   Accuracy |   Recall |   Specificity |\n",
      "+============+============+==========+===============+\n",
      "| 10-fold CV |      0.823 | 0.842245 |      0.757591 |\n",
      "+------------+------------+----------+---------------+\n",
      "| 2-fold CV  |      0.832 | 0.847738 |      0.779211 |\n",
      "+------------+------------+----------+---------------+\n"
     ]
    }
   ],
   "source": [
    "#The result of 10-fold cross validation\n",
    "# assign data\n",
    "mydata_ten = [[\"Accuracy\"] + accuracy_cv_list_10] + [[\"Recall\"] + recall_cv_list_10] + [[\"Specificity\"] + specificity_cv_list_10]\n",
    "# create header\n",
    "head_ten = [\"Execute order\"] + list(range(1,11)) \n",
    "# display table\n",
    "print(tabulate(mydata_ten, headers=head_ten, tablefmt=\"grid\"))\n",
    "\n",
    "#The comparison between 2-fold and 10-fold\n",
    "# assign data\n",
    "mydata1 = [[\"10-fold CV\"] + [np.mean(accuracy_cv_list_10)] + [np.mean(recall_cv_list_10)] + [np.mean(specificity_cv_list_10)]]\n",
    "mydata2 = [[\"2-fold CV\"] + [np.mean(accuracy_cv_list_2)] + [np.mean(recall_cv_list_2)] + [np.mean(specificity_cv_list_2)]]\n",
    "mydata_tt = mydata1 + mydata2\n",
    "# create header\n",
    "head = [\" \"] + [\"Accuracy\"]+ [\"Recall\"] + [\"Specificity\"]\n",
    "# display table\n",
    "print(tabulate(mydata_tt, headers=head, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "(a) \n",
    "Based on the \"Accuracy\" plot, the Gaussian algorithm has higher overall accuracy than the KDE algorithm, besides the case when the bandwidth is 3. The KED algorithm's accuracy shifts around 0.82, while the Gaussian algorithm's accuracy is 0.86. This phenomenon reveals that the Gaussian algorithm performs better in this dataset.\n",
    "\n",
    "By observing the histograms of the numeric attributes, their overall distributions are a bit similar to the Gaussian distribution, especially the \"Age\" and \"Hours per week\". Since Gaussian naive Bayes usually performs better in predicting data with Gaussian distribution, the Gaussian algorithm has higher accuracy and it's more suitable for this dataset. However, when the data distribution is far from the Gaussian distribution, KED naive Bayes may perform better. \n",
    "\n",
    "(b)\n",
    "By observing the first table, the 10-fold CV's accuracy, recall, and specificity are about 0.8. And the second table shows the 2-fold CV performs a bit better than the 10-fold CV. That shows that a less m value may lead to a better result, but it is hard to determine if it's a coincidence. The greater m may display a worse result, but it's closer to the realistic performance of the model since it trains more data and tests more times. Furthermore, the increasing value of m will also lead to a longer execution time, so it's important to pick a proper m value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 [4 marks]\n",
    "In `train()`, you are asked to treat the missing value of nominal attributes as a new category. There is another option (as suggested in Thu lecture in week 2): <u>ignoring the missing values</u>. \n",
    "Compare the two methods in both large and small datasets. Comment and explain your observations.\n",
    "You can extract the first 50 records to construct a small dataset.Use Gaussian Naive Bayes only for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write additional code here, if necessary (you may insert additional code cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide your text answer of 150-200 words in this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 [4 marks]\n",
    "In week 4, we have learned how to obtain information gain (IG) and gain ratio (GR) to choose an attribute to split a node in a decision tree. We will see how to apply them in the Naive Bayes classification.\n",
    "\n",
    "(a) Compute the GR of each attribute $X_i$, relative to the class distribution. In the Na\\\"ive Bayes classifier, remove attributes in the ascending order of GR: first, remove $P(X_i|c_j)$ such that $X_i$ has the least GR; second, remove $P(X_{i'}|c_j)$ such that $X_{i'}$ has the second least GR,......, until there is only one $X_{i*}$ with the largest GR remaining in the maximand $P(c_j) P(X_{i^*} | c_j)$. Observe the <u>change of the accuracy for both Gaussian and KDE</u> (Choose bandwidth $\\sigma=10$ for KDE).\n",
    "\n",
    "(b) Compute the IG between each pair of attributes. Describe and explain your observations. Choose an attribute and implement an estimator to predict the value of `education num`. Explain why you choose this attribute. Enumerate two other examples that an attribute can be used to estimate the other and explain the reason.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write additional code here, if necessary (you may insert additional code cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide your text answer to **Question 4.a** of 100-150 words in this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide your text answer to **Question 4.b** of 150-200 words in this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Authorship Declaration</b>:\n",
    "\n",
    "   (1) I certify that the program contained in this submission is completely\n",
    "   my own individual work, except where explicitly noted by comments that\n",
    "   provide details otherwise.  I understand that work that has been developed\n",
    "   by another student, or by me in collaboration with other students,\n",
    "   or by non-students as a result of request, solicitation, or payment,\n",
    "   may not be submitted for assessment in this subject.  I understand that\n",
    "   submitting for assessment work developed by or in collaboration with\n",
    "   other students or non-students constitutes Academic Misconduct, and\n",
    "   may be penalized by mark deductions, or by other penalties determined\n",
    "   via the University of Melbourne Academic Honesty Policy, as described\n",
    "   at https://academicintegrity.unimelb.edu.au.\n",
    "\n",
    "   (2) I also certify that I have not provided a copy of this work in either\n",
    "   softcopy or hardcopy or any other form to any other student, and nor will\n",
    "   I do so until after the marks are released. I understand that providing\n",
    "   my work to other students, regardless of my intention or any undertakings\n",
    "   made to me by that other student, is also Academic Misconduct.\n",
    "\n",
    "   (3) I further understand that providing a copy of the assignment\n",
    "   specification to any form of code authoring or assignment tutoring\n",
    "   service, or drawing the attention of others to such services and code\n",
    "   that may have been made available via such a service, may be regarded\n",
    "   as Student General Misconduct (interfering with the teaching activities\n",
    "   of the University and/or inciting others to commit Academic Misconduct).\n",
    "   I understand that an allegation of Student General Misconduct may arise\n",
    "   regardless of whether or not I personally make use of such solutions\n",
    "   or sought benefit from such actions.\n",
    "\n",
    "   <b>Signed by</b>: [Lingpeng Xiao 1025301]\n",
    "   \n",
    "   <b>Dated</b>: [2022/Apr./03]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
